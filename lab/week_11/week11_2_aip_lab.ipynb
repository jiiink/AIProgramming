{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7hzb8tP7lO"
      },
      "source": [
        "# Hill Climber Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1S1KALY3psI"
      },
      "source": [
        "|   | Hill Climbing Algorithm | Neighbor Generation                       | Number of Neighbors    | Termination                                   | Exploration vs. Exploitation |\n",
        "|---|-------------------------|-------------------------------------------|------------------------|-----------------------------------------------|------------------------------|\n",
        "| V | First-choice            | Random neighbor, stops when better found  | 1 until better found   | No improvement for a set number of iterations | Mostly exploitation          |\n",
        "| V | Steepest Ascent         | All possible neighbors, best selected     | All possible neighbors | No better neighbor found                      | Pure exploitation            |\n",
        "|   | Gradient Descent        | Next point based on gradient              | 1                      | No improvement in next step                   | Pure exploitation            |\n",
        "|   | Stochastic              | Multiple neighbors, chosen stochastically | Multiple               | No improvement for a set number of iterations | Mostly exploitation          |\n",
        "|   | Simulated Annealing     | Random neighbor                           | 1                      | Temperature reaches zero or eval limit        | Balanced                     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uj49mEmRTlL"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/John-Hogden/publication/291419889/figure/fig2/AS:320895026515974@1453518744135/Schematic-showing-the-trade-off-between-exploration-and-exploitation-A-hypothetical.png\" width=400>\n",
        "\n",
        "> Schematic showing the trade-off between **exploration** and **exploitation**.: A hypothetical fitness landscape (shown as continuous red line) from the regression model in an abstract high-dimensional feature space with two local maxima. One of the maxima has a data point with a relatively large value for mean, but small uncertainty (error bar). This is due to its close proximity to the best material that is known so far in the training set (blue circle), where the regression algorithm has trained well. The other local maximum, in contrast, has a data point with small mean value (red circle), but relatively large uncertainty.\n",
        "\n",
        "Prasanna V. Balachandran et. al., Adaptive Strategies for Materials Design using Uncertainties (2016)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrbmVQPZmyUH"
      },
      "source": [
        " # Scikit-learn Convention\n",
        "\n",
        "The Scikit-learn convention typically follows a certain approach, but in our classes, we frequently encounter problems that require finding the minimum value of a cost or objective function. Therefore, **our implementation adopts a method that is contrary to the standard Scikit-learn convention**.\n",
        "\n",
        " https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        " > All scorer objects follow **the convention that higher return values are better than lower return values**. Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, are available as neg_mean_squared_error which return the negated value of the metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ptW40mosp1kr"
      },
      "outputs": [],
      "source": [
        "class HillClimber:\n",
        "  def __init__(self, generate_neighbor,\n",
        "                objective_function,\n",
        "                initial_solution_generator,\n",
        "                step_size=0.1,\n",
        "                num_neighbors=1,\n",
        "                max_iter=1000,\n",
        "                num_restarts=10,\n",
        "                ):\n",
        "    self.generate_neighbor = generate_neighbor\n",
        "    self.objective_function = objective_function\n",
        "    self.initial_solution_generator = initial_solution_generator\n",
        "    self.step_size = step_size\n",
        "    self.num_neighbors = num_neighbors\n",
        "    self.max_iter = max_iter\n",
        "    self.num_restarts = num_restarts\n",
        "    self.best_solution = None\n",
        "    self.best_score = float('inf')\n",
        "\n",
        "  def fit(self):\n",
        "    self.current_solution = self.initial_solution_generator()\n",
        "    for _ in range(self.max_iter):\n",
        "      neighbors = self.generate_neighbor(solution=self.current_solution, step_size=self.step_size, num_neighbors=self.num_neighbors)\n",
        "      neighbors_scores = [self.objective_function(neighbor) for neighbor in neighbors]\n",
        "      best_neighbor_index = np.argmin(neighbors_scores)\n",
        "      best_neighbor = neighbors[best_neighbor_index]\n",
        "\n",
        "      if neighbors_scores[best_neighbor_index] < self.best_score:\n",
        "        self.best_solution = best_neighbor\n",
        "        self.best_score = neighbors_scores[best_neighbor_index]\n",
        "        self.current_solution = best_neighbor\n",
        "\n",
        "    return self.best_solution\n",
        "\n",
        "  def predict(self):\n",
        "    return self.best_solution\n",
        "\n",
        "  def score(self):\n",
        "    return self.best_score\n",
        "\n",
        "  def random_restart(self):\n",
        "    for _ in range(self.num_restarts):\n",
        "      self.fit()\n",
        "      new_solution = self.predict()\n",
        "      new_score = self.score()\n",
        "\n",
        "      if new_score < self.best_score:\n",
        "        self.best_solution = new_solution\n",
        "        self.best_score = new_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVNobvMYlmK4"
      },
      "source": [
        "# 5. SimulatedAnnealingHillClimber"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJA83R-wyNGI"
      },
      "source": [
        "## Acceptance Probability\n",
        "\n",
        "* Determine whether to move to the neighbor solution or stay with the current solution. This is where the temperature comes into play.\n",
        "\n",
        "* If the neighbor solution is better, it is always accepted.\n",
        "\n",
        "* If it is worse, it may still be accepted with a probability\n",
        "\n",
        "$$ \\alpha e^{-\\frac{ùö´E}{T}} $$\n",
        "\n",
        "where:\n",
        "\n",
        "* Œ± is The normalizing factor. We have treated\n",
        " Œ± as 1\n",
        "\n",
        "* ùö´E is the increase in energy (cost). In the our class, cost difference is next.SCORE ‚àí current.SCORE\n",
        "\n",
        "* T is the current temperature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtJ0HUvM5xQL"
      },
      "source": [
        "## Cooling Schedule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3vHGjV96NHz"
      },
      "source": [
        "| FAST                | SLOW     |\n",
        "|---------------------|----------|\n",
        "| <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/SimulatedAnnealingFast.jpg/384px-SimulatedAnnealingFast.jpg\"> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/SimulatedAnnealingSlow.jpg/384px-SimulatedAnnealingSlow.jpg\" > |\n",
        "\n",
        "> Example illustrating the effect of cooling schedule on the performance of simulated annealing. The problem is to rearrange the pixels of an image so as to minimize a certain potential energy function, which causes similar colors to attract at short range and repel at a slightly larger distance. The elementary moves swap two adjacent pixels. These images were obtained with a fast cooling schedule (left) and a slow cooling schedule (right), producing results similar to amorphous and crystalline solids, respectively.\n",
        "\n",
        "ref. https://en.wikipedia.org/wiki/Simulated_annealing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3tR9Cjw6q2J"
      },
      "source": [
        "## Pseudocode\n",
        "\n",
        "```\n",
        "Let s = s0\n",
        "For k = 0 through kmax (exclusive):\n",
        "    T ‚Üê temperature( 1 - (k+1)/kmax )\n",
        "    Pick a random neighbour, snew ‚Üê neighbour(s)\n",
        "    If P(E(s), E(snew), T) ‚â• random(0, 1):\n",
        "      s ‚Üê snew\n",
        "Output: the final state s\n",
        "```\n",
        "\n",
        "* The following pseudocode presents the simulated annealing heuristic as described above.\n",
        "* It **starts from a state s0** and continues until a maximum of kmax steps have been taken.\n",
        "* In the process, the call **neighbour(s)** should generate a **randomly chosen neighbour** of a given state s;\n",
        "* The call **random(0, 1)** should pick and return a value in **the range [0, 1], uniformly at random**.\n",
        "* The annealing schedule is defined by the call **temperature(r)**, which should yield the temperature to use, given the fraction r of the time budget that has been expended so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l8onvgsul6-9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class SimulatedAnnealingHillClimber(HillClimber):\n",
        "  def __init__(self, generate_neighbor, objective_function, initial_solution_generator, step_size=0.1, num_neighbors=1, max_iter=10000, num_restarts=10, temperature=1.0, alpha=1.0):\n",
        "    super().__init__(generate_neighbor, objective_function, initial_solution_generator, step_size, num_neighbors, max_iter, num_restarts)\n",
        "    self.temperature = temperature\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def _acceptance_probability(self, cur_cost, new_cost):\n",
        "    # self.alpha * pow((new_cost - cur_cost), \n",
        "    return np.exp(-(new_cost - cur_cost) / (self.temperature + 1e-2))\n",
        "    pass\n",
        "\n",
        "  def _cooling_schedule(self, k):\n",
        "    self.temperature *= (1.0 - ((k + 1.0) / self.max_iter))\n",
        "    pass\n",
        "\n",
        "  def fit(self):\n",
        "    self.current_solution = self.initial_solution_generator()\n",
        "    print(\"initial_solution\", self.current_solution)\n",
        "    for k in range(self.max_iter):\n",
        "      self._cooling_schedule(k)\n",
        "      neighbors = self.generate_neighbor(solution=self.current_solution, step_size=self.step_size, num_neighbors=self.num_neighbors)\n",
        "\n",
        "      neighbors_scores = [self.objective_function(neighbor) for neighbor in neighbors]\n",
        "\n",
        "      best_neighbor_index = np.argmin(neighbors_scores)\n",
        "\n",
        "      best_neighbor = neighbors[best_neighbor_index]\n",
        "\n",
        "      if neighbors_scores[best_neighbor_index] < self.best_score:\n",
        "        self.best_solution = best_neighbor\n",
        "        self.best_score = neighbors_scores[best_neighbor_index]\n",
        "        self.current_solution = best_neighbor\n",
        "      elif self._acceptance_probability(self.best_score, neighbors_scores[best_neighbor_index]) >= random.uniform(0, 1):\n",
        "        neighbors = self.generate_neighbor(solution=self.current_solution, step_size=self.step_size, num_neighbors=self.num_neighbors)\n",
        "        neighbors_scores = [self.objective_function(neighbor) for neighbor in neighbors]\n",
        "        best_neighbor_index = np.argmin(neighbors_scores)\n",
        "        best_neighbor = neighbors[best_neighbor_index]\n",
        "\n",
        "    return self.best_solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrkZJnBy_7OV",
        "outputId": "5d3003c5-cd30-46f0-b363-fa5668e09a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial_solution [8.469852732187228, 17.301367003497283, -11.038040980227002, 22.457875691066313, -0.7099705216045784]\n",
            "Gradient Descent Hill Climber Best Solution: [ 1.99770441  5.00662205 -8.00385917 -1.01072007  7.00467708]\n",
            "Gradient Descent Hill Climber Best Score: 0.00082\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "def objective_function(x):\n",
        "    return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "\n",
        "\n",
        "def continuous_generate_neighbor(solution, step_size, num_neighbors):\n",
        "    neighbors = []\n",
        "    for _ in range(num_neighbors):\n",
        "        neighbors.append(solution + np.random.uniform(-step_size, step_size, len(solution)))\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "def initial_solution_generator(n=5):\n",
        "    return [np.random.uniform(-30, 30) for _ in range(n)]\n",
        "\n",
        "\n",
        "# Test the GradientDescentHillClimber class\n",
        "hill_climber = SimulatedAnnealingHillClimber(\n",
        "    generate_neighbor=continuous_generate_neighbor,\n",
        "    objective_function=objective_function,\n",
        "    initial_solution_generator=initial_solution_generator,\n",
        ")\n",
        "\n",
        "hill_climber.fit()\n",
        "\n",
        "print(f\"Gradient Descent Hill Climber Best Solution: {hill_climber.predict()}\")\n",
        "print(f\"Gradient Descent Hill Climber Best Score: {hill_climber.score():.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDbksKnRA8M_",
        "outputId": "0c922993-35eb-4827-e6f3-ea3c03fde410"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Define the TSP environment\n",
        "cities = [\n",
        "    (8, 31), (54, 97), (50, 50), (65, 16), (70, 47), (25, 100), (55, 74), (77, 87),\n",
        "    (6, 46), (70, 78), (13, 38), (100, 32), (26, 35), (55, 16), (26, 77), (17, 67),\n",
        "    (40, 36), (38, 27), (33, 2), (48, 9), (62, 20), (17, 92), (30, 2), (80, 75),\n",
        "    (32, 36), (43, 79), (57, 49), (18, 24), (96, 76), (81, 39)\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsPk_819Nm9N"
      },
      "source": [
        "# 1. FirstChoiceHillClimber\n",
        "\n",
        "Given the base class HillClimber, implement a FirstChoiceHillClimber class that extends the functionality of hill climbing by selecting the first neighboring solution that is better than the current solution. Override the fit method to perform the hill climbing process, predict to return the best solution found, and score to return the objective value of the best solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OPsgKsUWQGI8"
      },
      "outputs": [],
      "source": [
        "class FirstChoiceHillClimber(HillClimber):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3ep3TEHMv_l"
      },
      "source": [
        "#2. SteepestAscentHillClimber\n",
        "\n",
        "\n",
        "Using the provided HillClimber class, create a SteepestAscentHillClimber class that finds the best neighbor out of all possible neighbor solutions generated in one iteration and moves to it if it is better than the current solution. Implement fit, predict, and score methods according to the class' operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3uEjfo5l8mfM"
      },
      "outputs": [],
      "source": [
        "class SteepestAscentHillClimber(HillClimber):\n",
        "  def fit(self):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOH6d9g7QkOn"
      },
      "source": [
        "#3. GradientDescentHillClimber\n",
        "\n",
        "GradientDescentHillClimber class using the convex_function as the objective function. We will test these classes to see if they can minimize this function, starting from a random initial solution in a 5-dimensional space.\n",
        "\n",
        "```\n",
        "def convex_function(x):\n",
        "    return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UPvzCtWi6YoK"
      },
      "outputs": [],
      "source": [
        "class GradientDescentHillClimber(HillClimber):\n",
        "    def __init__(self, gradient_function, objective_function, initial_solution_generator, step_size=0.1, num_neighbors=1, learning_rate=0.01, max_iter=1000, mode='min', num_restarts=10):\n",
        "      super().__init__(gradient_function, objective_function, initial_solution_generator, step_size, num_neighbors, max_iter, mode, num_restarts)\n",
        "      self.learning_rate = learning_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DudJvXNo6agn"
      },
      "source": [
        "# 4. RandomRestartHillClimber ??\n",
        "\n",
        "Random Restart is a strategy used to overcome the limitations of local search algorithms, which might get stuck in local optima. The idea is to run a local search algorithm repeatedly from different random starting points.\n",
        "\n",
        "> Compared to these algorithms (FirstChoice, Steepest, GradientDescent), the random restart mechanism is actually a different approach.\n",
        "\n",
        "```\n",
        "for _ in range(num_restarts):\n",
        "  algorithm.fit()\n",
        "  new_solution = algorithm.predict()\n",
        "  new_score = algorithm.score()\n",
        "  if (is_better(best_score, new_score):\n",
        "    best_solution = new_solution\n",
        "    best_score = new_score\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vRqOey9I6ewJ"
      },
      "outputs": [],
      "source": [
        "# xxxx.random_restart()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxXTtUHHQ8n-"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgiWOgNv2R6J"
      },
      "source": [
        "\n",
        "\n",
        "| Ackley | Griewank | Convex |\n",
        "|------|----------|-----|\n",
        "| <img src=\"https://drive.google.com/uc?id=1M1slit0Toi9fSt5A_XFPLHdC73vue9-_\" width=\"400\"/>   | <img src=\"https://drive.google.com/uc?id=1dz2iCffrUXVa7bB4ohxjvDXPp3ud0vTO\" width=\"400\"/>      |   <img src=\"https://drive.google.com/uc?id=1FRXc3t5WQlKRWHT_sj7xfhocITK3-RoW\" width=\"400\"/>  |\n",
        "\n",
        "```\n",
        "def ackley_function(x):\n",
        "    term1 = -20 * math.exp(-0.2 * math.sqrt(sum(xi ** 2 for xi in x) / len(x)))\n",
        "    term2 = -math.exp(sum(math.cos(2 * math.pi * xi) for xi in x) / len(x))\n",
        "    return 20 + math.e + term1 + term2\n",
        "\n",
        "def convex_function(x):\n",
        "    return (x[0] - 2) ** 2 + 5 * (x[1] - 5) ** 2 + 8 * (x[2] + 8) ** 2 + 3 * (x[3] + 1) ** 2 + 6 * (x[4] - 7) ** 2\n",
        "\n",
        "def griewank_function(x):\n",
        "    sum_term = sum(xi ** 2 for xi in x) / 4000\n",
        "    prod_term = math.cos(x[0])\n",
        "    for i, xi in enumerate(x[1:], start=2):\n",
        "        prod_term *= math.cos(xi / math.sqrt(i))\n",
        "    return 1 + sum_term - prod_term\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC03wvHwOHjk"
      },
      "source": [
        "# 0. Discrete Problem Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S5TkwI0GOHLv"
      },
      "outputs": [],
      "source": [
        "cities = [\n",
        "    (8, 31), (54, 97), (50, 50), (65, 16), (70, 47), (25, 100), (55, 74), (77, 87),\n",
        "    (6, 46), (70, 78), (13, 38), (100, 32), (26, 35), (55, 16), (26, 77), (17, 67),\n",
        "    (40, 36), (38, 27), (33, 2), (48, 9), (62, 20), (17, 92), (30, 2), (80, 75),\n",
        "    (32, 36), (43, 79), (57, 49), (18, 24), (96, 76), (81, 39)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQTQkVBu4JAa"
      },
      "source": [
        "# Version History\n",
        "\n",
        "VERSION 0.4:\n",
        "* Removed learning_rate as it's more specific to gradient descent. Streamlined other parameters.\n",
        "* Aligning with the common practice in optimization of minimizing a cost or objective function.\n",
        "* Simplified the neighbor evaluation process. Directly uses np.argmin for finding the best neighbor, assuming minimization problems.\n",
        "\n",
        "\n",
        "VERSION 0.3:\n",
        "* Removed current_solution initialization from the constructor.\n",
        "* Added num_neighbor to control the number of neighbors generated per iteration.\n",
        "* Added best_score_idx, a lambda function to find the index of the best score from a list of scores. This is used when evaluating multiple neighbors.\n",
        "* The current solution is now initialized at the start of the fit method.\n",
        "* Generates multiple neighbors (num_neighbor) per iteration and evaluates them.\n",
        "* Selects the best neighbor based on the scores and updates the current and best solutions if necessary.\n",
        "* Implements the random restart mechanism. It calls fit method multiple times (num_restarts) and keeps track of the overall best solution.\n",
        "\n",
        "\n",
        "VERSION 0.2:\n",
        "* Introduced the mode parameter to toggle between maximization and minimization.\n",
        "* Added a lambda function, is_better, to abstract the comparison logic based on the mode.\n",
        "* The best_score is now set based on the mode of operation.\n",
        "* The fit method is updated to use the is_better function for comparison.\n",
        "\n",
        "\n",
        "\n",
        "VERSION 0.1:\n",
        "* Basic hill climbing functionality to maximize an objective function.\n",
        "* The fit method only seeks to improve (maximize) the objective function score.\n",
        "* The best_score is initialized to negative infinity to ensure any score is better.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
